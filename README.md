# AI4Devs - GPT Assistant Integration

## Contenido

- [AI4Devs - GPT Assistant Integration](#ai4devs---gpt-assistant-integration)
  - [Contenido](#contenido)
  - [Introducci贸n](#introducci贸n)
  - [Versi贸n](#versi贸n)
  - [Configuraci贸n del asistente customizado](#configuraci贸n-del-asistente-customizado)
    - [System Instructions:](#system-instructions)
    - [Model:](#model)
    - [Model Configuration](#model-configuration)
      - [Response Format:](#response-format)
      - [Temperature:](#temperature)
  - [C贸mo integrar el asistente en tu aplicaci贸n:](#c贸mo-integrar-el-asistente-en-tu-aplicaci贸n)
  - [Caso de uso](#caso-de-uso)
    - [Costes](#costes)
  - [Referencias](#referencias)

## Introducci贸n

Este proyecto es un ejemplo sencillo de c贸mo **_integrar un asistente GPT personalizado_** en una aplicaci贸n web, lo que nos permite a los desarrolladores agregar capacidades de conversaci贸n automatizada e interacci贸n inteligente a sus plataformas.

La integraci贸n de un asistente GPT nos puede ayudar a abordar varias necesidades, como:

- **Interacci贸n personalizada**: Los usuarios de hoy en d铆a esperan experiencias que se ajusten a sus preferencias y necesidades espec铆ficas, como obtener recomendaciones, resolver dudas o recibir asistencia en tiempo real. La integraci贸n de un asistente inteligente permite una interacci贸n din谩mica y personalizada, aumentando la satisfacci贸n del usuario al ofrecer respuestas y sugerencias precisas en funci贸n de sus solicitudes.

- **Automatizaci贸n del soporte**: En plataformas con un gran volumen de usuarios, la automatizaci贸n del soporte es clave para mantener la calidad sin aumentar costos. Un sistema de IA puede gestionar eficientemente una amplia gama de consultas, desde preguntas frecuentes hasta tareas repetitivas, lo que libera recursos humanos para centrarse en situaciones m谩s complejas y de mayor valor.

- **Escalabilidad**: A medida que una aplicaci贸n o plataforma crece, es esencial que el soporte y la interacci贸n con los usuarios puedan expandirse sin afectar el rendimiento. La inteligencia artificial facilita la escalabilidad al manejar m煤ltiples interacciones simult谩neas, proporcionando una asistencia r谩pida y eficaz sin sobrecargar los sistemas ni requerir m谩s personal de soporte.

- **Mejora de la experiencia del usuario**: Adem谩s de resolver consultas, los asistentes virtuales pueden ser configurados para guiar a los usuarios a trav茅s de procesos complejos, sugerir opciones relevantes o facilitar la navegaci贸n en la plataforma. Este tipo de soporte proactivo y fluido contribuye significativamente a una experiencia de usuario m谩s agradable y eficiente.

Este tipo de integraciones abren nuevas oportunidades para mejorar la interacci贸n con nuestras aplicaciones, permitiendo ofrecer un valor a帽adido que las haga m谩s atractivas y competitivas en el mercado actual.

## Versi贸n

OpenAI-Beta: **assistants=v2**

Lanzamiento, abril 2024: _[platform.openai.com/docs/assistants/whats-new](https://platform.openai.com/docs/assistants/whats-new)_

## Configuraci贸n del asistente customizado

Accede a tu cuenta de OpenAI y crea un nuevo proyecto: [platform.openai.com/playground](https://platform.openai.com/playground)

![step1](./media/step1.png)

Una vez dispongas de tu proyecto, accede a la secci贸n de **Playground/Assistants** para crear tu nuevo asistente.

![step2](./media/step2.png)

Dispondr谩s de varias propiedades para configurar tu asistente. En este tutorial nos centraremos en las siguientes secciones:

### System Instructions:

Indicaremos al asistente las instrucciones generales que debe seguir para responder a las consultas de los usuarios. Estas instrucciones deben ser claras y directas, proporcionando una gu铆a clara para el comportamiento del asistente pero tenemos que tener en cuenta que, a mayor complejidad en las instrucciones, el asistente tardar谩 m谩s en responder. Lo adecuado es depurar el comportamiento del asistente para obtener el mejor resultado lo cual puedes hacer en la misma interfaz de configuraci贸n.

Un ejemplo de estructura para las instrucciones generales podr铆a ser:

1. **Prop贸sito General**
2. **Informaci贸n M铆nima Requerida**
3. **Informaci贸n Adicional Opcional**
4. **Formato de la Respuesta**
5. **Flujo de Interacci贸n**
6. **Estilo y Tono**
7. **Ejemplos de Uso**

Recuerda servirte de herramientas y m茅todos de estructuraci贸n de texto para que el asistente pueda interpretar correctamente las instrucciones, por ejemplo, puedes usar markdown o json para ello.

Los compa帽eros de GuruSup, por ejemplo, recomiendan utilizar XML en su v铆deo: [El FIN de las Alucinaciones en los LLM | C贸mo aplicar los Prompts XML](https://www.youtube.com/watch?v=Whs0S2p8euA)

### Model:

Esta secci贸n nos permite seleccionar el modelo de lenguaje que queremos que use nuestro asistente. El modelo elegido condicionar谩 en gran medida la calidad de las respuestas que obtendremos en distintos niveles: velocidad, precisi贸n y coste.

### Model Configuration

#### Response Format:

Con esta nueva versi贸n de OpenAI Assistant API, podemos configurar el formato de respuesta del asistente, lo cual nos permite controlar si queremos que el asistente responda en texto plano como hace por defecto, con JSON a trav茅s de esta nueva propiedad o determinamos esta respuesta en el apartado **System Instructions**.

#### Temperature:

Con la propiedad **Temperature** podemos controlar la creatividad del asistente. Un valor de 0 har谩 que el asistente sea extremadamente preciso y conservador en sus respuestas, mientras que un valor superior puede hacer que el asistente sea m谩s creativo y original. **_El nivel de temperatura ideal depender谩 del objetivo que buscamos cubrir con nuestro asistente_**; para un asistente de soporte t茅cnico puede ser interesante un valor bajo, mientras que para un asistente de recomendaciones puede ser interesante un valor m谩s alto.

---

Dispones de m谩s informaci贸n para configurar tu asistente en la documentaci贸n oficial de OpenAI: 

- [platform.openai.com/docs/api-reference/assistants](https://platform.openai.com/docs/api-reference/assistants)
- [platform.openai.com/docs/assistants/tools](https://platform.openai.com/docs/assistants/tools)

## C贸mo integrar el asistente en tu aplicaci贸n:

Ahora que disponemos de nuestro asistente configurado, podemos integrarlo en nuestra aplicaci贸n. Para ello, necesitaremos:

1. Crear una API Key: 
   - Accederemos a esta secci贸n desde **[Dashboard/API Keys](https://platform.openai.com/api-keys)**

2. Obtener el ID de nuestro asistente:
   - Disponemos de este ID en varios puntos de nuestra interfaz de configuraci贸n, por ejemplo, en la secci贸n de **[Dashboard/Assistants](https://platform.openai.com/assistants)**:
     ![step3](./media/step3.png)

3. Obtener el ID de nuestro proyecto:
   - Accederemos a esta secci贸n desde **[Organization Overview/Projects](https://platform.openai.com/organization/projects)**
     ![step4](./media/step4.png)

4. Obtener el ID de nuestra organizaci贸n:
   - Accederemos a esta secci贸n desde **[Settings/Organization/General](https://platform.openai.com/settings/organization/general)**
     ![step5](./media/step5.png)

5. Utilizar el ID de nuestro asistente para crear un hilo de conversaci贸n y obtener el ID del hilo e iterar sobre el hilo para enviar mensajes al asistente (ejemplo en Node.js):
    ```js
    import OpenAI from "openai";

    async function main() {
        const openAIClient = new OpenAI({
            apiKey: {OUR_API_KEY},
            organization: {OUR_ORGANIZATION_ID},
            project: {OUR_PROJECT_ID},
        });

        const thread = await openAIClient.beta.threads.create();

        const message = await openAIClient.beta.threads.messages.create(
            thread.id,
            {
                role: "user",
                content: {USER_MESSAGE}
            }
        );

        const run = await openAIClient.beta.threads.runs.createAndPoll(
            thread.id,
            {
                assistant_id: {OUR_ASSISTANT_ID}  
            }
        );

        // Iteramos sobre el hilo para obtener/mostrar las respuestas del asistente
        if (run.status === 'completed') {
            const messages = await openAIClient.beta.threads.messages.list(run.thread_id);
            for (const message of messages.data.reverse()) {
                console.log(`${message.role} > ${message.content[0].text.value}`);
            }
        } else {
            console.log(run.status);
        }
    }

    main();
    ```

Para los ejemplos de c贸digo se ha tomado como referencia la [integraci贸n del asistente de forma as铆ncrona](https://platform.openai.com/docs/assistants/quickstart?context=without-streaming) pero esto depender谩 de lo que necesites en tu caso particular.

## Caso de uso

Esta modalidad de customizaci贸n se ha utilizado para uno de los proyectos finales de AI4Devs, en el cual se ha configurado un asistente personalizado para generar itinerarios de viaje a trav茅s de un chatbot.

Compartimos con vosotros las instrucciones finales del asistente y c贸mo se configur贸 la respuesta del mismo para facilitar el trabajo posterior de desarrollo y almacenamiento de la informaci贸n.

- [Instrucciones del asistente](./docs/instructions.md)
- [Configuraci贸n de la respuesta del asistente](./docs/real-response-example.md)

### Costes

Para poder visualizar los costes de utilizar un asistente personalizado, OpenAI nos ofrece una herramienta en la secci贸n de **[Dashboard/Usage](https://platform.openai.com/usage)**.

Para este aplicativo en particular, donde se utilizaron varios modelos hasta dar con el id贸neo y el tiempo de desarrollo se extendi贸 durante unas pocas semanas, el consumo medio fue de 150.000 tokens, unas 70 requests diarias, lo que se tradujo en un coste total de $6.72.

![costs](./media/costs.png)
 
## Referencias

- [API Overview | platform.openai.com/docs/overview](https://platform.openai.com/docs/overview)
- [Assistants Creation | platform.openai.com/docs/assistants/overview](https://platform.openai.com/docs/assistants/overview)
- [Assistants Integration | platform.openai.com/docs/assistants/quickstart](https://platform.openai.com/docs/assistants/quickstart)
